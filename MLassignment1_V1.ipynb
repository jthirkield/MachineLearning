{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Amazon.csv')\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###FIXING THE MISSING DATA IN THE SUMMARY COLUMN\n",
    "data['newSummary'] = np.where(pd.isnull(data['Summary']) == True, 'nn', data['Summary'])\n",
    "##GETTING A REPORT OF MISSING VALUES\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#features from Amazon.csv to add to feature set\n",
    "#pandas creating new columns in the data frame\n",
    "\n",
    "#length of the review\n",
    "data['reviewLen'] = data['Text'].str.len()\n",
    "#number of semi-colons\n",
    "data['hasSC'] = data['Text'].str.count(';')\n",
    "#number of exclaimation marks\n",
    "data['hasEX'] = data['Text'].str.count('!')\n",
    "#number of questions marks\n",
    "data['hasQ'] = data['Text'].str.count('\\?')\n",
    "#total common punctuation count\n",
    "data['punctCount'] = data['Text'].str.count('[.,!;:()/\\?-]')\n",
    "#ratio of punctuation to words\n",
    "data['punctToWords'] = data['punctCount'] / data['reviewLen']\n",
    "#average word length\n",
    "data['avWordLength'] = data['Text'].str.len() // (data['Text'].str.count(' ') + 1)\n",
    "#summary length\n",
    "data['sumLen'] = data['newSummary'].str.count('\\S')\n",
    "#summary average word length\n",
    "data['avSumWordLen'] = data['newSummary'].str.len() // (data['newSummary'].str.count(' ') + 1)\n",
    "#summary exclaimation marks\n",
    "data['sumHasEX'] = data['newSummary'].str.count('!')\n",
    "#summary question marks\n",
    "data['sumHasQ'] = data['newSummary'].str.count('\\?')\n",
    "\n",
    "data['date'] = pd.to_datetime(data['Time'],unit='s')\n",
    "###getting day of the week (maybe Sundays are better times to write reviews)\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "#score is less than four\n",
    "data['scoreType'] = np.where(data['Score'] < 4, 1, 0)\n",
    "\n",
    "    \n",
    "#wanted to get time of day but the timestamps only have dates...\n",
    "#data['time_of_day'] = data['date'].dt.hour\n",
    "\n",
    "#adjective to word ratio\n",
    "\n",
    "print(data.shape)\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##pulling out values and making them vectors\n",
    "XScore = data.iloc[:, 7].values.reshape(data.shape[0], 1)\n",
    "XreviewLen = data.iloc[:, 14].values.reshape(data.shape[0], 1)\n",
    "XhasSC = data.iloc[:, 15].values.reshape(data.shape[0], 1)\n",
    "XhasEX = data.iloc[:, 16].values.reshape(data.shape[0], 1)\n",
    "XhasQ = data.iloc[:, 17].values.reshape(data.shape[0], 1)\n",
    "XpunctCount = data.iloc[:, 18].values.reshape(data.shape[0], 1)\n",
    "XpunctToWords = data.iloc[:, 19].values.reshape(data.shape[0], 1)\n",
    "XavWordLength = data.iloc[:, 20].values.reshape(data.shape[0], 1)\n",
    "XsumLen = data.iloc[:, 21].values.reshape(data.shape[0], 1)\n",
    "XavSumWordLen = data.iloc[:, 22].values.reshape(data.shape[0], 1)\n",
    "XsumHasEX = data.iloc[:, 23].values.reshape(data.shape[0], 1)\n",
    "XsumHasQ = data.iloc[:, 24].values.reshape(data.shape[0], 1)\n",
    "#Xdate = data.iloc[:, 24].values.reshape(data.shape[0], 1)\n",
    "Xday_of_week = data.iloc[:, 26].values.reshape(data.shape[0], 1)\n",
    "XscoreType = data.iloc[:, 27].values.reshape(data.shape[0], 1)\n",
    "#Xtoadd = np.concatenate((XScore, XreviewLen, XhasSC, XhasEX, XhasQ, XpunctCount, XpunctToWords, XavWordLength, Xday_of_week, XscoreType), axis=1)\n",
    "Xtoadd = np.concatenate((XScore, XreviewLen, XhasSC, XhasEX, XhasQ, XpunctCount, XpunctToWords, XavWordLength, XsumLen, XavSumWordLen, XsumHasEX, XsumHasQ, Xday_of_week, XscoreType), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report on training and test sets\n",
    "def print_results():\n",
    "    print('Error rate on training set: ')\n",
    "    print((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('Accuracy rate on training set: ')\n",
    "    print(1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('True positive rate on training tet:')\n",
    "    print(((y_train==True) & (y_pred==True)).sum() / y_train.sum())\n",
    "    print('**************')\n",
    "    print('Error rate on test set: ')\n",
    "    print((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('Accuracy rate on test set: ')\n",
    "    print(1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('True positive rate on test set')\n",
    "    print(((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    print('True negative rate on test set')\n",
    "    print(((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#restricting to 2 to the power of 17 features\n",
    "hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "X = hv.transform(data.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "XtoaddSparse = csr_matrix(Xtoadd)\n",
    "Xfinal = hstack([X, XtoaddSparse])\n",
    "X = csr_matrix(Xfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# size of feature set\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define y\n",
    "y = data.iloc[:, 12].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MODEL: SVM, linear defaults to Scaled Vector Machine\n",
    "#incrementing each weight to reduce cost (defaults five passes)\n",
    "# dealing with two vectors weights over and over\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MODEL: logistic regression\n",
    "#log parameter, meaning logistic / tinker with alpha \n",
    "#here alpha is the regularization parameter  (default is 0.0001)\n",
    "#here more penalizing the weights (hope to stop overfitting)\n",
    "#need to specific the seed so that it doesn't totally randomize\n",
    "#could loop through alphas and graph the accuracy rate\n",
    "#could graphic the cost function and see when the number of iterations plateau\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MODEL: Naive Bayes\n",
    "#this improved the true positives / maybe a different model for true positives\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
