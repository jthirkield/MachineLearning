{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138806</td>\n",
       "      <td>138807</td>\n",
       "      <td>B000E63LME</td>\n",
       "      <td>A1CQGW1AOD0LF2</td>\n",
       "      <td>Alena K. \"Alena\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>Not as pictured.</td>\n",
       "      <td>I was looking forward to try cranberry apple f...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469680</td>\n",
       "      <td>469681</td>\n",
       "      <td>B004ZIH4KM</td>\n",
       "      <td>A37S7U1OX2MCWI</td>\n",
       "      <td>Becky Cole</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349740800</td>\n",
       "      <td>seeds</td>\n",
       "      <td>TY for everything.  The seeds arrived quickly,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238202</td>\n",
       "      <td>238203</td>\n",
       "      <td>B003ZXE9QA</td>\n",
       "      <td>A2OM6G73E64EQ9</td>\n",
       "      <td>jeff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329264000</td>\n",
       "      <td>I'm addicted!</td>\n",
       "      <td>I've finally found the best cereal in the worl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>485307</td>\n",
       "      <td>485308</td>\n",
       "      <td>B001RVFERK</td>\n",
       "      <td>A25W349EE97NBK</td>\n",
       "      <td>Tangent4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1248307200</td>\n",
       "      <td>I wanted to love these...</td>\n",
       "      <td>I originally bought these chips because I'd he...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375283</td>\n",
       "      <td>375284</td>\n",
       "      <td>B000OQZNTS</td>\n",
       "      <td>A3CPPW0HUC07YS</td>\n",
       "      <td>Amy Nicolai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333238400</td>\n",
       "      <td>Excellent chamomile tea</td>\n",
       "      <td>Really excellent tea, flowers are visible in t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id   ProductId          UserId       ProfileName  \\\n",
       "0      138806  138807  B000E63LME  A1CQGW1AOD0LF2  Alena K. \"Alena\"   \n",
       "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI        Becky Cole   \n",
       "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9              jeff   \n",
       "3      485307  485308  B001RVFERK  A25W349EE97NBK          Tangent4   \n",
       "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS       Amy Nicolai   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       2      2  1294185600   \n",
       "1                     0                       0      5  1349740800   \n",
       "2                     0                       0      5  1329264000   \n",
       "3                     1                       1      4  1248307200   \n",
       "4                     0                       0      5  1333238400   \n",
       "\n",
       "                     Summary  \\\n",
       "0           Not as pictured.   \n",
       "1                      seeds   \n",
       "2              I'm addicted!   \n",
       "3  I wanted to love these...   \n",
       "4    Excellent chamomile tea   \n",
       "\n",
       "                                                Text  helpScore helpful  \n",
       "0  I was looking forward to try cranberry apple f...        0.5   False  \n",
       "1  TY for everything.  The seeds arrived quickly,...        NaN   False  \n",
       "2  I've finally found the best cereal in the worl...        NaN   False  \n",
       "3  I originally bought these chips because I'd he...        1.0   False  \n",
       "4  Really excellent tea, flowers are visible in t...        NaN   False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('Amazon.csv')\n",
    "print(data1.shape)\n",
    "data1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290787, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>helpScore</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469680</td>\n",
       "      <td>469681</td>\n",
       "      <td>B004ZIH4KM</td>\n",
       "      <td>A37S7U1OX2MCWI</td>\n",
       "      <td>Becky Cole</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349740800</td>\n",
       "      <td>seeds</td>\n",
       "      <td>TY for everything.  The seeds arrived quickly,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238202</td>\n",
       "      <td>238203</td>\n",
       "      <td>B003ZXE9QA</td>\n",
       "      <td>A2OM6G73E64EQ9</td>\n",
       "      <td>jeff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329264000</td>\n",
       "      <td>I'm addicted!</td>\n",
       "      <td>I've finally found the best cereal in the worl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375283</td>\n",
       "      <td>375284</td>\n",
       "      <td>B000OQZNTS</td>\n",
       "      <td>A3CPPW0HUC07YS</td>\n",
       "      <td>Amy Nicolai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333238400</td>\n",
       "      <td>Excellent chamomile tea</td>\n",
       "      <td>Really excellent tea, flowers are visible in t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>530491</td>\n",
       "      <td>530492</td>\n",
       "      <td>B001E5DX90</td>\n",
       "      <td>A26XS571YR9XPF</td>\n",
       "      <td>Briana B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1191628800</td>\n",
       "      <td>Better than Coffee</td>\n",
       "      <td>I never was a big fan of tea but this is not l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>355114</td>\n",
       "      <td>355115</td>\n",
       "      <td>B000IGAE66</td>\n",
       "      <td>A1WFG6OC3PPGZ</td>\n",
       "      <td>N. Myhre</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1293321600</td>\n",
       "      <td>Great Ceasers Ghost- These Cakes Are Great</td>\n",
       "      <td>WOW WOW WOW WOW,WOW,truly great tasting Banana...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id   ProductId          UserId  ProfileName  \\\n",
       "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI   Becky Cole   \n",
       "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9         jeff   \n",
       "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS  Amy Nicolai   \n",
       "5      530491  530492  B001E5DX90  A26XS571YR9XPF     Briana B   \n",
       "6      355114  355115  B000IGAE66   A1WFG6OC3PPGZ     N. Myhre   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "1                     0                       0      5  1349740800   \n",
       "2                     0                       0      5  1329264000   \n",
       "4                     0                       0      5  1333238400   \n",
       "5                     0                       0      5  1191628800   \n",
       "6                     0                       0      5  1293321600   \n",
       "\n",
       "                                      Summary  \\\n",
       "1                                       seeds   \n",
       "2                               I'm addicted!   \n",
       "4                     Excellent chamomile tea   \n",
       "5                          Better than Coffee   \n",
       "6  Great Ceasers Ghost- These Cakes Are Great   \n",
       "\n",
       "                                                Text  helpScore helpful  \n",
       "1  TY for everything.  The seeds arrived quickly,...        NaN   False  \n",
       "2  I've finally found the best cereal in the worl...        NaN   False  \n",
       "4  Really excellent tea, flowers are visible in t...        NaN   False  \n",
       "5  I never was a big fan of tea but this is not l...        NaN   False  \n",
       "6  WOW WOW WOW WOW,WOW,truly great tasting Banana...        NaN   False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data1[(data1.Score == 5)]\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     0\n",
       "Id                             0\n",
       "ProductId                      0\n",
       "UserId                         0\n",
       "ProfileName                   10\n",
       "HelpfulnessNumerator           0\n",
       "HelpfulnessDenominator         0\n",
       "Score                          0\n",
       "Time                           0\n",
       "Summary                        0\n",
       "Text                           0\n",
       "helpScore                 149690\n",
       "helpful                        0\n",
       "newSummary                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###FIXING THE MISSING DATA IN THE SUMMARY COLUMN\n",
    "data['newSummary'] = np.where(pd.isnull(data['Summary']) == True, 'nn', data['Summary'])\n",
    "##GETTING A REPORT OF MISSING VALUES\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290787, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>...</th>\n",
       "      <th>sumLen</th>\n",
       "      <th>avSumWordLen</th>\n",
       "      <th>sumHasEX</th>\n",
       "      <th>sumHasQ</th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>scoreType</th>\n",
       "      <th>newScore</th>\n",
       "      <th>newScore2</th>\n",
       "      <th>newScore3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469680</td>\n",
       "      <td>469681</td>\n",
       "      <td>B004ZIH4KM</td>\n",
       "      <td>A37S7U1OX2MCWI</td>\n",
       "      <td>Becky Cole</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1349740800</td>\n",
       "      <td>seeds</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-09</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238202</td>\n",
       "      <td>238203</td>\n",
       "      <td>B003ZXE9QA</td>\n",
       "      <td>A2OM6G73E64EQ9</td>\n",
       "      <td>jeff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1329264000</td>\n",
       "      <td>I'm addicted!</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-02-15</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375283</td>\n",
       "      <td>375284</td>\n",
       "      <td>B000OQZNTS</td>\n",
       "      <td>A3CPPW0HUC07YS</td>\n",
       "      <td>Amy Nicolai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1333238400</td>\n",
       "      <td>Excellent chamomile tea</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>530491</td>\n",
       "      <td>530492</td>\n",
       "      <td>B001E5DX90</td>\n",
       "      <td>A26XS571YR9XPF</td>\n",
       "      <td>Briana B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1191628800</td>\n",
       "      <td>Better than Coffee</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-10-06</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>355114</td>\n",
       "      <td>355115</td>\n",
       "      <td>B000IGAE66</td>\n",
       "      <td>A1WFG6OC3PPGZ</td>\n",
       "      <td>N. Myhre</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1293321600</td>\n",
       "      <td>Great Ceasers Ghost- These Cakes Are Great</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-12-26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Id   ProductId          UserId  ProfileName  \\\n",
       "1      469680  469681  B004ZIH4KM  A37S7U1OX2MCWI   Becky Cole   \n",
       "2      238202  238203  B003ZXE9QA  A2OM6G73E64EQ9         jeff   \n",
       "4      375283  375284  B000OQZNTS  A3CPPW0HUC07YS  Amy Nicolai   \n",
       "5      530491  530492  B001E5DX90  A26XS571YR9XPF     Briana B   \n",
       "6      355114  355115  B000IGAE66   A1WFG6OC3PPGZ     N. Myhre   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "1                     0                       0      5  1349740800   \n",
       "2                     0                       0      5  1329264000   \n",
       "4                     0                       0      5  1333238400   \n",
       "5                     0                       0      5  1191628800   \n",
       "6                     0                       0      5  1293321600   \n",
       "\n",
       "                                      Summary    ...     sumLen  avSumWordLen  \\\n",
       "1                                       seeds    ...          5             5   \n",
       "2                               I'm addicted!    ...         12             6   \n",
       "4                     Excellent chamomile tea    ...         21             7   \n",
       "5                          Better than Coffee    ...         16             6   \n",
       "6  Great Ceasers Ghost- These Cakes Are Great    ...         36             6   \n",
       "\n",
       "  sumHasEX sumHasQ       date  day_of_week  scoreType  newScore  newScore2  \\\n",
       "1        0       0 2012-10-09            1          5         0          0   \n",
       "2        1       0 2012-02-15            2          5         0          0   \n",
       "4        0       0 2012-04-01            6          5         0          0   \n",
       "5        0       0 2007-10-06            5          5         0          0   \n",
       "6        0       0 2010-12-26            6          5         0          0   \n",
       "\n",
       "   newScore3  \n",
       "1          0  \n",
       "2          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features from Amazon.csv to add to feature set\n",
    "#pandas creating new columns in the data frame\n",
    "\n",
    "#length of the review\n",
    "data['reviewLen'] = data['Text'].str.len()\n",
    "#number of semi-colons\n",
    "data['hasSC'] = data['Text'].str.count(';')\n",
    "#number of exclaimation marks\n",
    "data['hasEX'] = data['Text'].str.count('!')\n",
    "#number of questions marks\n",
    "data['hasQ'] = data['Text'].str.count('\\?')\n",
    "#total common punctuation count\n",
    "data['punctCount'] = data['Text'].str.count('[.,!;:()/\\?-]')\n",
    "#ratio of punctuation to words\n",
    "data['punctToWords'] = data['punctCount'] / data['reviewLen']\n",
    "#average word length\n",
    "data['avWordLength'] = data['Text'].str.len() // (data['Text'].str.count(' ') + 1)\n",
    "#summary length\n",
    "data['sumLen'] = data['newSummary'].str.count('\\S')\n",
    "#summary average word length\n",
    "data['avSumWordLen'] = data['newSummary'].str.len() // (data['newSummary'].str.count(' ') + 1)\n",
    "#summary exclaimation marks\n",
    "data['sumHasEX'] = data['newSummary'].str.count('!')\n",
    "#summary question marks\n",
    "data['sumHasQ'] = data['newSummary'].str.count('\\?')\n",
    "\n",
    "data['date'] = pd.to_datetime(data['Time'],unit='s')\n",
    "###getting day of the week (maybe Sundays are better times to write reviews)\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "#score is less than four\n",
    "##data['scoreType'] = np.where(data['Score'] < 4, 1, 0)\n",
    "data['scoreType'] = data['Score']\n",
    "#data['newScore'] = np.where(data['HelpfulnessDenominator'] > 2 & data['HelpfulnessDenominator']/data['HelpfulnessNumerator'] > 0.65, 1, 0)\n",
    "#chaning y -- newScore is an helpful ratio over 65% -- this one is more predictive for true postives...\n",
    "data['newScore'] = np.where(data['HelpfulnessNumerator']/data['HelpfulnessDenominator'] > 0.65, 1, 0)\n",
    "data['newScore2'] = np.where(data['HelpfulnessDenominator'] > 2, 1, 0)\n",
    "data['newScore3'] = np.where(data['newScore'] + data['newScore2'] == 2, 1, 0)\n",
    "\n",
    "    \n",
    "#wanted to get time of day but the timestamps only have dates...\n",
    "#data['time_of_day'] = data['date'].dt.hour\n",
    "\n",
    "#adjective to word ratio\n",
    "\n",
    "print(data.shape)\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##pulling out values and making them vectors\n",
    "XScore = data.iloc[:, 7].values.reshape(data.shape[0], 1)\n",
    "XreviewLen = data.iloc[:, 14].values.reshape(data.shape[0], 1)\n",
    "XhasSC = data.iloc[:, 15].values.reshape(data.shape[0], 1)\n",
    "XhasEX = data.iloc[:, 16].values.reshape(data.shape[0], 1)\n",
    "XhasQ = data.iloc[:, 17].values.reshape(data.shape[0], 1)\n",
    "XpunctCount = data.iloc[:, 18].values.reshape(data.shape[0], 1)\n",
    "XpunctToWords = data.iloc[:, 19].values.reshape(data.shape[0], 1)\n",
    "XavWordLength = data.iloc[:, 20].values.reshape(data.shape[0], 1)\n",
    "XsumLen = data.iloc[:, 21].values.reshape(data.shape[0], 1)\n",
    "XavSumWordLen = data.iloc[:, 22].values.reshape(data.shape[0], 1)\n",
    "XsumHasEX = data.iloc[:, 23].values.reshape(data.shape[0], 1)\n",
    "XsumHasQ = data.iloc[:, 24].values.reshape(data.shape[0], 1)\n",
    "#Xdate = data.iloc[:, 24].values.reshape(data.shape[0], 1)\n",
    "Xday_of_week = data.iloc[:, 26].values.reshape(data.shape[0], 1)\n",
    "XscoreType = data.iloc[:, 27].values.reshape(data.shape[0], 1)\n",
    "#Xtoadd = np.concatenate((XScore, XreviewLen, XhasSC, XhasEX, XhasQ, XpunctCount, XpunctToWords, XavWordLength, Xday_of_week, XscoreType), axis=1)\n",
    "Xtoadd = np.concatenate((XScore, XreviewLen, XhasSC, XhasEX, XhasQ, XpunctCount, XpunctToWords, XavWordLength, XsumLen, XavSumWordLen, XsumHasEX, XsumHasQ, Xday_of_week, XscoreType), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# report on training and test sets\n",
    "def print_results():\n",
    "    print('Error rate on training set: ')\n",
    "    print((y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('Accuracy rate on training set: ')\n",
    "    print(1 - (y_train != y_pred).sum() / X_train.shape[0])\n",
    "    print('True positive rate on training tet:')\n",
    "    print(((y_train==True) & (y_pred==True)).sum() / y_train.sum())\n",
    "    print('**************')\n",
    "    print('Error rate on test set: ')\n",
    "    print((y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('Accuracy rate on test set: ')\n",
    "    print(1 - (y_test != y_pred_test).sum() / X_test.shape[0])\n",
    "    print('True positive rate on test set')\n",
    "    print(((y_test==True) & (y_pred_test==True)).sum() / y_test.sum())\n",
    "    print('True negative rate on test set')\n",
    "    print(((y_test==False) & (y_pred_test==False)).sum() / (y_test.shape[0] - y_test.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "#from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#restricting to 2 to the power of 17 features\n",
    "#hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "#X = hv.transform(data.Text)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1, ngram_range=(2,3))\n",
    "X = vectorizer.fit_transform(data.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#sumVectorizer = TfidfVectorizer(min_df=1, ngram_range=(1,1))\n",
    "sumVectorizer = CountVectorizer(min_df=1, binary = True)\n",
    "#sumVectorizer = CountVectorizer()\n",
    "sumX = sumVectorizer.fit_transform(data.newSummary)\n",
    "#vectorizer = CountVectorizer()\n",
    "#X = vectorizer.fit_transform(data.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert additional features to sparse matrix and concatenate onto the bag of words sparse matrix\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "XtoaddSparse = csr_matrix(Xtoadd)\n",
    "Xfinal = hstack([X, sumX, XtoaddSparse])\n",
    "#Xfinal = hstack([XtoaddSparse])\n",
    "X = csr_matrix(Xfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290787, 8362667)\n"
     ]
    }
   ],
   "source": [
    "# size of feature set\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290787,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define y\n",
    "y = data.iloc[:, 28].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.00329648734955\n",
      "Accuracy rate on training set: \n",
      "0.99670351265\n",
      "True positive rate on training tet:\n",
      "0.996016171045\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.302257069821\n",
      "Accuracy rate on test set: \n",
      "0.697742930179\n",
      "True positive rate on test set\n",
      "0.673907677117\n",
      "True negative rate on test set\n",
      "0.71485682776\n"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear defaults to Scaled Vector Machine\n",
    "#incrementing each weight to reduce cost (defaults five passes)\n",
    "# dealing with two vectors weights over and over\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.00200933431589\n",
      "Accuracy rate on training set: \n",
      "0.997990665684\n",
      "True positive rate on training tet:\n",
      "0.997560199427\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.302841684148\n",
      "Accuracy rate on test set: \n",
      "0.697158315852\n",
      "True positive rate on test set\n",
      "0.670424312241\n",
      "True negative rate on test set\n",
      "0.716353538934\n"
     ]
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "#log parameter, meaning logistic / tinker with alpha \n",
    "#here alpha is the regularization parameter  (default is 0.0001)\n",
    "#here more penalizing the weights (hope to stop overfitting)\n",
    "#need to specific the seed so that it doesn't totally randomize\n",
    "#could loop through alphas and graph the accuracy rate\n",
    "#could graphic the cost function and see when the number of iterations plateau\n",
    "from sklearn import linear_model\n",
    "#clf = linear_model.SGDClassifier(loss='log', n_iter=100, penalty='elasticnet',alpha=0.00001)\n",
    "clf = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.00269712601326\n",
      "Accuracy rate on training set: \n",
      "0.997302873987\n",
      "True positive rate on training tet:\n",
      "0.995544711997\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.302130976535\n",
      "Accuracy rate on test set: \n",
      "0.697869023465\n",
      "True positive rate on test set\n",
      "0.717874873145\n",
      "True negative rate on test set\n",
      "0.683504667376\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "#this improved the true positives / maybe a different model for true positives\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: \n",
      "0.00330631294522\n",
      "Accuracy rate on training set: \n",
      "0.996693687055\n",
      "True positive rate on training tet:\n",
      "0.995261836569\n",
      "**************\n",
      "Error rate on test set: \n",
      "0.304125543061\n",
      "Accuracy rate on test set: \n",
      "0.695874456939\n",
      "True positive rate on test set\n",
      "0.671192298198\n",
      "True negative rate on test set\n",
      "0.713596439403\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(loss='perceptron')\n",
    "clf.fit(X_train_std, y_train)\n",
    "y_pred = clf.fit(X_train_std, y_train).predict(X_train_std)\n",
    "y_pred_test = clf.predict(X_test_std)\n",
    "print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
